# Copyright (c) Forward Email LLC
# SPDX-License-Identifier: BUSL-1.1

---
- name: Import security playbook
  import_playbook: security.yml
- name: Import SSH keys playbook
  import_playbook: ssh-keys.yml
- name: Import UFW allowlist playbook for MongoDB
  import_playbook: ufw-allowlist.yml
  vars:
    target_hosts: mongo
    service_name: MongoDB
    service_port_var: MONGO_PORT
    service_port_default: "27017"
    service_identifier: mongo
    ufw_comment: "Auto-whitelist MongoDB"

- name: Import high-traffic sysctl tuning for MongoDB
  import_playbook: sysctl-high-traffic.yml
  vars:
    target_hosts: mongo
    service_name: MongoDB
    sysctl_file_name: mongodb

- name: Import I/O and filesystem tuning for MongoDB
  import_playbook: io-filesystem-tuning.yml
  vars:
    target_hosts: mongo
    service_name: MongoDB
    service_identifier: mongo
    data_directory: /var/lib/mongodb
    read_ahead_kb: 16


- hosts: mongo
  name: Certificate Paths
  vars_prompt:
    - name: input_key
      prompt: "Enter path to certificate private key file on local machine (e.g. /path/to/.ssl-key) [REQUIRED]"
      private: false
    - name: input_cert
      prompt: "Enter path to certificate full chain/certificate file on local machine (e.g. /path/to/.ssl-cert) [REQUIRED]"
      private: false
    - name: input_ca
      prompt: "Enter path to certificate CA bundle file on local machine (e.g. /path/to/.ssl-ca) [REQUIRED]"
      private: false
  tasks:
    - name: Fail if key path is empty
      fail:
        msg: "Certificate private key path is required. Please re-run the playbook and provide a valid path."
      when: (input_key is not defined) or (input_key | length == 0)

    - name: Fail if cert path is empty
      fail:
        msg: "Certificate file path is required. Please re-run the playbook and provide a valid path."
      when: (input_cert is not defined) or (input_cert | length == 0)

    - name: Fail if CA path is empty
      fail:
        msg: "CA bundle file path is required. Please re-run the playbook and provide a valid path."
      when: (input_ca is not defined) or (input_ca | length == 0)

    - name: Check if key file exists locally
      local_action: stat path={{ input_key }}
      become: false
      register: local_key_file

    - name: Fail when local key file does not exist
      fail:
        msg: "key file does not exist: {{ input_key }}"
      when: not local_key_file.stat.exists

    - name: Check if cert file exists locally
      local_action: stat path={{ input_cert }}
      become: false
      register: local_cert_file

    - name: Fail when local cert file does not exist
      fail:
        msg: "cert file does not exist: {{ input_cert }}"
      when: not local_cert_file.stat.exists

    - name: Check if CA file exists locally
      local_action: stat path={{ input_ca }}
      become: false
      register: local_ca_file

    - name: Fail when local CA file does not exist
      fail:
        msg: "CA file does not exist: {{ input_ca }}"
      when: not local_ca_file.stat.exists

    - name: Store certificate paths as facts
      set_fact:
        ssl_key_path: "{{ input_key }}"
        ssl_cert_path: "{{ input_cert }}"
        ssl_ca_path: "{{ input_ca }}"

- hosts: mongo
  name: Hostname
  become: true
  become_user: root
  tasks:
    - name: Validate required environment variables
      assert:
        that:
          - lookup('env', 'MONGO_HOST') != ''
          - lookup('env', 'MONGO_PORT') != ''
          - lookup('env', 'AWS_ACCESS_KEY_ID') != ''
          - lookup('env', 'AWS_SECRET_ACCESS_KEY') != ''
          - lookup('env', 'AWS_ENDPOINT_URL') != ''
          - lookup('env', 'BACKUP_SECRET') != ''
        fail_msg: |
          Required environment variables are missing for MongoDB playbook.
          Please ensure the following variables are set in your .env file:
          - MONGO_HOST
          - MONGO_PORT
          - SSL_CERT_PATH
          - SSL_KEY_PATH
          - SSL_CA_PATH
          - AWS_ACCESS_KEY_ID
          - AWS_SECRET_ACCESS_KEY
          - AWS_ENDPOINT_URL
          - BACKUP_SECRET
        quiet: false

    - name: Set hostname
      hostname:
        name: "{{ lookup('env', 'MONGO_HOST') }}"

- hosts: mongo
  name: MongoDB
  become: true
  become_user: root
  handlers:
    - name: Reload UFW
      ufw:
        state: reloaded
    # NOTE: MongoDB restart removed - must be done manually
    # See post-deployment instructions for manual restart procedure
  tasks:
    # MongoDB-specific sysctl optimizations
    # Note: Common high-traffic settings imported from sysctl-high-traffic.yml
    # These are MongoDB-specific additions
    - name: Configure MongoDB-specific sysctl parameters
      ansible.builtin.sysctl:
        name: "{{ item.name }}"
        value: "{{ item.value }}"
        state: present
        reload: true
        sysctl_file: /etc/sysctl.d/99-mongodb-specific.conf
      loop:
        - { name: 'vm.max_map_count', value: '262144' }  # Required for MongoDB WiredTiger storage engine

    # Configure swap for MongoDB stability
    # MongoDB requires swap to prevent OOM crashes during high memory usage
    # Best practice: swap file size = total system RAM
    - name: Get total system memory in MB
      shell: free -m | awk '/^Mem:/{print $2}'
      register: total_memory_mb
      changed_when: false

    - name: Check if swap file exists
      stat:
        path: /swapfile
      register: swapfile_stat

    - name: Check current swap size
      shell: swapon --show=SIZE --noheadings --bytes | head -1
      register: current_swap_bytes
      changed_when: false
      failed_when: false

    - name: Calculate required swap size in bytes
      set_fact:
        required_swap_mb: "{{ total_memory_mb.stdout | int }}"
        required_swap_bytes: "{{ (total_memory_mb.stdout | int) * 1024 * 1024 }}"

    - name: Disable existing swap if size doesn't match
      command: swapoff /swapfile
      when:
        - swapfile_stat.stat.exists
        - current_swap_bytes.stdout != ""
        - current_swap_bytes.stdout | int != required_swap_bytes | int
      ignore_errors: true

    - name: Remove old swap file if size doesn't match
      file:
        path: /swapfile
        state: absent
      when:
        - swapfile_stat.stat.exists
        - current_swap_bytes.stdout != ""
        - current_swap_bytes.stdout | int != required_swap_bytes | int

    - name: Create swap file with size equal to RAM
      command: fallocate -l {{ required_swap_mb }}M /swapfile
      args:
        creates: /swapfile

    - name: Set swap file permissions
      file:
        path: /swapfile
        mode: '0600'
        owner: root
        group: root

    - name: Format swap file
      command: mkswap /swapfile
      when: not swapfile_stat.stat.exists or (current_swap_bytes.stdout | int != required_swap_bytes | int)
      register: mkswap_result
      changed_when: "'Setting up swapspace' in mkswap_result.stdout"

    - name: Enable swap file
      command: swapon /swapfile
      when: mkswap_result is changed

    - name: Add swap to /etc/fstab
      lineinfile:
        path: /etc/fstab
        line: '/swapfile none swap sw 0 0'
        state: present
        regexp: '^/swapfile'

    - name: Set swappiness for MongoDB (minimize swapping but allow it for safety)
      ansible.builtin.sysctl:
        name: vm.swappiness
        value: '1'
        state: present
        reload: true
        sysctl_file: /etc/sysctl.d/99-mongodb.conf

    # Install MongoDB using custom installation (no Galaxy role)
    # WARNING: DO NOT upgrade to MongoDB 7.0 or 8.0 due to severe performance regressions
    # MongoDB 7.0 has been reported to be up to 25x slower than 6.0 for index-based queries
    # MongoDB 8.0's "36% faster" claim is compared to 7.0, NOT 6.0
    # Root causes: Slot-Based Execution engine issues and WiredTiger ticket reduction
    # Forward Email's query patterns (aggregations, index lookups, regex) are directly affected
    # References:
    # - https://www.mongodb.com/community/forums/t/performance-drop-after-upgrade-6-0-10-7-0-1/246712
    # - https://revisit.tech/blog/mongodb-8-0-performanace-is-36-percent-higher-but-there-is-a-catch/
    # - https://dev.to/manoj_from_revisit_dot_tech/mongodb-80-performance-is-36-higher-nope-its-not--35jk
    
    - name: Remove old MongoDB GPG keys
      file:
        path: "{{ item }}"
        state: absent
      loop:
        - /usr/share/keyrings/mongodb-server-6.0.gpg
        - /etc/apt/trusted.gpg.d/mongodb-server-6.0.gpg

    - name: Add MongoDB GPG key
      apt_key:
        url: https://www.mongodb.org/static/pgp/server-6.0.asc
        state: present
      register: gpg_key_added

    - name: Remove old MongoDB repository file
      file:
        path: /etc/apt/sources.list.d/mongodb-org-6.0.list
        state: absent

    - name: Add MongoDB repository
      apt_repository:
        repo: "deb [ arch=amd64,arm64 ] https://repo.mongodb.org/apt/ubuntu {{ ansible_distribution_release }}/mongodb-org/6.0 multiverse"
        state: present
        filename: mongodb-org-6.0
        update_cache: yes
      register: repo_added

    - name: Update apt cache after repository changes
      apt:
        update_cache: yes
      when: gpg_key_added.changed or repo_added.changed

    - name: Install MongoDB 6.0.18
      apt:
        name:
          - mongodb-org=6.0.18
          - mongodb-org-database=6.0.18
          - mongodb-org-server=6.0.18
          - mongodb-org-mongos=6.0.18
          - mongodb-org-tools=6.0.18
        state: present
        update_cache: yes

    - name: Hold MongoDB packages to prevent accidental upgrades
      dpkg_selections:
        name: "{{ item }}"
        selection: hold
      loop:
        - mongodb-org
        - mongodb-org-database
        - mongodb-org-server
        - mongodb-org-mongos
        - mongodb-org-tools

    - name: Ensure mongodb group exists
      group:
        name: mongodb
        system: yes
        state: present

    - name: Ensure mongodb user exists
      user:
        name: mongodb
        group: mongodb
        system: yes
        shell: /usr/sbin/nologin
        home: /var/lib/mongodb
        createhome: no
        state: present

    - name: Ensure MongoDB data directory exists
      file:
        path: /var/lib/mongodb
        state: directory
        owner: mongodb
        group: mongodb
        mode: '0755'

    - name: Ensure MongoDB log directory exists
      file:
        path: /var/log/mongodb
        state: directory
        owner: mongodb
        group: mongodb
        mode: '0755'

    - name: Reload systemd daemon
      systemd:
        daemon_reload: yes

    - name: Check if mongod service file exists
      stat:
        path: /lib/systemd/system/mongod.service
      register: mongod_service_file

    - name: Fail if mongod service file is missing
      fail:
        msg: "MongoDB service file not found. Package installation may have failed."
      when: not mongod_service_file.stat.exists

    - name: Enable and start mongod service
      systemd:
        name: mongod
        enabled: yes
        state: started

    # Add failure notification to mongod service
    - name: Create mongod service override directory
      file:
        path: /etc/systemd/system/mongod.service.d
        state: directory
        owner: root
        group: root
        mode: '0755'

    - name: Add OnFailure notification to mongod service
      copy:
        dest: /etc/systemd/system/mongod.service.d/failure-notification.conf
        content: |
          # WARNING: This file is managed by Ansible
          # Manual changes will be overwritten on next deployment
          [Unit]
          OnFailure=failure-notification@%n.service
        owner: root
        group: root
        mode: '0644'

    - name: Reload systemd daemon for mongod override
      systemd:
        daemon_reload: yes

    # Configure MongoDB for TLS/SSL
    - name: Ensure MongoDB TLS/SSL configuration directory exists
      file:
        path: /etc/mongodb/ssl
        state: directory
        owner: mongodb
        group: mongodb
        mode: "0750"

    # Copy SSL certificates directly from local machine to MongoDB directory
    - name: Copy SSL certificate to MongoDB directory
      copy:
        src: "{{ hostvars[inventory_hostname]['ssl_cert_path'] }}"
        dest: /etc/mongodb/ssl/mongodb.crt
        owner: mongodb
        group: mongodb
        mode: "0400"

    - name: Copy SSL private key to MongoDB directory
      copy:
        src: "{{ hostvars[inventory_hostname]['ssl_key_path'] }}"
        dest: /etc/mongodb/ssl/mongodb.key
        owner: mongodb
        group: mongodb
        mode: "0400"

    - name: Copy CA certificate to MongoDB directory
      copy:
        src: "{{ hostvars[inventory_hostname]['ssl_ca_path'] }}"
        dest: /etc/mongodb/ssl/ca.pem
        owner: mongodb
        group: mongodb
        mode: "0400"

    - name: Create MongoDB TLS/SSL certificate PEM file (cert + key)
      shell: |
        cat /etc/mongodb/ssl/mongodb.crt /etc/mongodb/ssl/mongodb.key > /etc/mongodb/ssl/mongodb.pem
        chown mongodb:mongodb /etc/mongodb/ssl/mongodb.pem
        chmod 0400 /etc/mongodb/ssl/mongodb.pem
      args:
        creates: /etc/mongodb/ssl/mongodb.pem

    - name: Configure MongoDB TLS/SSL in mongod.conf
      blockinfile:
        path: /etc/mongod.conf
        marker: "# {mark} ANSIBLE MANAGED BLOCK - TLS/SSL"
        block: |
          net:
            tls:
              mode: requireTLS
              certificateKeyFile: /etc/mongodb/ssl/mongodb.pem
              CAFile: /etc/mongodb/ssl/ca.pem

    # Create admin user if authentication is not yet enabled
    - name: Check if admin user exists
      shell: |
        mongosh --quiet --eval "db.adminCommand('listUsers').users.length" admin 2>/dev/null || echo "0"
      register: admin_user_check
      changed_when: false
      failed_when: false

    - name: Copy MongoDB user creation Python script
      copy:
        src: files/create_mongo_user.py
        dest: /tmp/create_mongo_user.py
        mode: '0700'
      no_log: true

    - name: Create MongoDB user creation script using Python
      shell: |
        export MONGO_USER='{{ lookup('env', 'MONGO_USER') }}'
        export MONGO_PASS='{{ lookup('env', 'MONGO_PASS') }}'
        python3 /tmp/create_mongo_user.py
      register: script_creation
      failed_when: false
      no_log: true

    - name: Check Python script result
      fail:
        msg: "Failed to create MongoDB user creation script"
      when: script_creation.rc != 0

    - name: Create MongoDB admin user
      shell: |
        mongosh --quiet admin --file /tmp/create_mongo_user.js
      register: create_user_result
      failed_when: false
      no_log: true

    - name: Remove temporary MongoDB scripts
      file:
        path: "{{ item }}"
        state: absent
      loop:
        - /tmp/create_mongo_user.py
        - /tmp/create_mongo_user.js
      no_log: true

    - name: Check MongoDB user creation result
      fail:
        msg: "Failed to create MongoDB admin user"
      when: >
        create_user_result.rc != 0 and
        'User already exists' not in create_user_result.stdout and
        'User created successfully' not in create_user_result.stdout

    - name: Enable MongoDB authentication in mongod.conf
      blockinfile:
        path: /etc/mongod.conf
        marker: "# {mark} ANSIBLE MANAGED BLOCK - SECURITY"
        block: |
          security:
            authorization: enabled

    - name: Configure MongoDB connection limits
      blockinfile:
        path: /etc/mongod.conf
        marker: "# {mark} ANSIBLE MANAGED BLOCK - NET CONFIG"
        block: |
          net:
            maxIncomingConnections: 65536
            port: {{ lookup('env', 'MONGO_PORT') | default('27017', true) }}

    # Disable mongosh telemetry globally
    - name: Create mongosh config directory
      file:
        path: /home/{{ item }}/.mongodb/mongosh
        state: directory
        owner: "{{ item }}"
        group: "{{ item }}"
        mode: '0755'
      loop:
        - root
        - deploy
      ignore_errors: true

    - name: Disable mongosh telemetry for all users
      copy:
        dest: /home/{{ item }}/.mongodb/mongosh/config
        content: |
          {
            "enableTelemetry": false,
            "disableGreetingMessage": true
          }
        owner: "{{ item }}"
        group: "{{ item }}"
        mode: '0644'
      loop:
        - root
        - deploy
      ignore_errors: true

    # UFW Configuration - Using reusable playbook
    # See ufw-allowlist.yml for implementation details

    # Install AWS CLI and GPG dependencies
    - name: Install AWS CLI and GPG dependencies
      apt:
        name:
          - python3-pip
          - unzip
          - gnupg
        update_cache: true

    - name: Install AWS CLI
      shell: |
        if ! command -v aws &> /dev/null; then
          curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "/tmp/awscliv2.zip"
          unzip -q /tmp/awscliv2.zip -d /tmp
          /tmp/aws/install
          rm -rf /tmp/aws /tmp/awscliv2.zip
        fi
      args:
        creates: /usr/local/bin/aws

    # Create MongoDB backup script
    - name: Create MongoDB backup script
      copy:
        dest: /usr/local/bin/backup-mongodb.sh
        mode: "0755"
        content: |
          #!/bin/bash
          set -e
          exec 2>&1  # Redirect stderr to stdout for journal logging

          echo "Starting MongoDB backup at $(date -u +%Y-%m-%dT%H:%M:%SZ)"

          # Environment variables (set via systemd service or environment)
          AWS_ACCESS_KEY_ID="${AWS_ACCESS_KEY_ID}"
          AWS_SECRET_ACCESS_KEY="${AWS_SECRET_ACCESS_KEY}"
          AWS_ENDPOINT_URL="${AWS_ENDPOINT_URL}"
          AWS_DEFAULT_REGION="${AWS_DEFAULT_REGION:-auto}"
          BACKUP_BUCKET="${MONGO_BACKUP_BUCKET:-forwardemail-backups}"
          BACKUP_SECRET="${BACKUP_SECRET}"
          MONGO_PORT="${MONGO_PORT:-27017}"

          # Check if BACKUP_SECRET is set
          if [ -z "$BACKUP_SECRET" ]; then
            ERROR_MSG="BACKUP_SECRET environment variable is not set"
            echo "ERROR: $ERROR_MSG"
            /usr/local/bin/send-rate-limited-email.sh "mongodb-backup" "[ERROR] MongoDB Backup Failed on $(hostname)" "$ERROR_MSG"
            exit 1
          fi

          # Timestamp and path (flat structure - no folder nesting)
          BACKUP_NAME="mongo-backup-$(date -u +%Y-%m-%dT%H:%M:%SZ).gz.gpg"
          S3_PATH="s3://${BACKUP_BUCKET}/mongo/${BACKUP_NAME}"

          echo "Backup destination: ${S3_PATH}"

          # Check if bucket exists, create if not
          echo "Checking if S3 bucket exists: ${BACKUP_BUCKET}"
          if ! aws s3 ls "s3://${BACKUP_BUCKET}" --endpoint-url="${AWS_ENDPOINT_URL}" >/dev/null 2>&1; then
            echo "Bucket does not exist, creating: ${BACKUP_BUCKET}"
            if ! aws s3 mb "s3://${BACKUP_BUCKET}" --endpoint-url="${AWS_ENDPOINT_URL}" 2>&1; then
              ERROR_MSG="Failed to create S3 bucket ${BACKUP_BUCKET} at $(date -u +%Y-%m-%dT%H:%M:%SZ)"
              echo "ERROR: $ERROR_MSG"
              /usr/local/bin/send-rate-limited-email.sh "mongodb-backup" "[ERROR] MongoDB Backup Failed on $(hostname)" "$ERROR_MSG"
              exit 1
            fi
            echo "Bucket created successfully: ${BACKUP_BUCKET}"

            # Harden bucket security
            echo "Applying security hardening to bucket..."

            # Block public access (R2 specific)
            if aws s3api put-public-access-block \
              --bucket "${BACKUP_BUCKET}" \
              --public-access-block-configuration "BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true" \
              --endpoint-url="${AWS_ENDPOINT_URL}" 2>/dev/null; then
              echo "âœ“ Public access blocked"
            else
              echo "âš  Could not set public access block (may not be supported by R2)"
            fi

            # Set private ACL
            if aws s3api put-bucket-acl \
              --bucket "${BACKUP_BUCKET}" \
              --acl private \
              --endpoint-url="${AWS_ENDPOINT_URL}" 2>/dev/null; then
              echo "âœ“ Bucket ACL set to private"
            else
              echo "âš  Could not set bucket ACL (may not be supported by R2)"
            fi

            echo "Bucket security hardening completed"
          else
            echo "Bucket exists: ${BACKUP_BUCKET}"
          fi

          # Perform backup, encrypt with GPG, and stream directly to S3
          echo "Starting mongodump on localhost:${MONGO_PORT}..."
          if ! mongodump --host=localhost --port="${MONGO_PORT}" --oplog --archive --gzip 2>&1 | \
            gpg --symmetric --cipher-algo AES256 --batch --yes --passphrase "$BACKUP_SECRET" | \
            aws s3 cp - "${S3_PATH}" --endpoint-url="${AWS_ENDPOINT_URL}" 2>&1; then
            ERROR_MSG="Failed to backup/encrypt/upload MongoDB at $(date -u +%Y-%m-%dT%H:%M:%SZ). Check MongoDB connection and AWS credentials."
            echo "ERROR: $ERROR_MSG"
            /usr/local/bin/send-rate-limited-email.sh "mongodb-backup" "[ERROR] MongoDB Backup Failed on $(hostname)" "$ERROR_MSG"
            exit 1
          fi

          echo "MongoDB encrypted backup completed: ${S3_PATH}"
          echo "Backup finished at $(date -u +%Y-%m-%dT%H:%M:%SZ)"

    # Create MongoDB backup cleanup script
    - name: Create MongoDB backup cleanup script
      copy:
        dest: /usr/local/bin/cleanup-mongodb-backups.sh
        mode: "0755"
        content: |
          #!/bin/bash
          set -e
          exec 2>&1  # Redirect stderr to stdout for journal logging

          echo "Starting MongoDB backup cleanup at $(date -u +%Y-%m-%dT%H:%M:%SZ)"

          # Environment variables
          AWS_ACCESS_KEY_ID="${AWS_ACCESS_KEY_ID}"
          AWS_SECRET_ACCESS_KEY="${AWS_SECRET_ACCESS_KEY}"
          AWS_ENDPOINT_URL="${AWS_ENDPOINT_URL}"
          AWS_DEFAULT_REGION="${AWS_DEFAULT_REGION:-auto}"
          BACKUP_BUCKET="${MONGO_BACKUP_BUCKET:-forwardemail-backups}"

          # Counters for reporting
          DELETED_OLD=0
          DELETED_DAILY=0
          KEPT_RECENT=0
          ERRORS=0

          # Calculate dates
          THIRTY_DAYS_AGO=$(date -d "30 days ago" +%s)
          SEVEN_DAYS_AGO=$(date -d "7 days ago" +%s)

          echo "Retention policy: Keep all backups < 7 days, one per day for 8-30 days, delete > 30 days"
          echo "Checking bucket: s3://${BACKUP_BUCKET}/mongo/"

          # List all backups and process
          if ! BACKUP_LIST=$(aws s3 ls s3://${BACKUP_BUCKET}/mongo/ --recursive --endpoint-url="${AWS_ENDPOINT_URL}" 2>&1); then
            ERROR_MSG="Failed to list backups in s3://${BACKUP_BUCKET}/mongo/ at $(date -u +%Y-%m-%dT%H:%M:%SZ). Error: ${BACKUP_LIST}"
            echo "ERROR: $ERROR_MSG"
            /usr/local/bin/send-rate-limited-email.sh "mongo-cleanup" "[ERROR] MongoDB Backup Cleanup Failed on $(hostname)" "$ERROR_MSG"
            exit 1
          fi

          # Process each backup
          echo "$BACKUP_LIST" | while read -r line; do
            # Skip empty lines
            [ -z "$line" ] && continue

            FILE_DATE=$(echo "$line" | awk '{print $1" "$2}')
            FILE_PATH=$(echo "$line" | awk '{print $4}')

            # Extract timestamp from filename (ISO 8601 format: mongo-backup-2025-11-27T19:50:03Z.gz.gpg)
            # Filename format: mongo-backup-YYYY-MM-DDTHH:MM:SSZ.gz.gpg
            FILENAME=$(basename "$FILE_PATH")
            ISO_TIMESTAMP=$(echo "$FILENAME" | grep -oP 'mongo-backup-\K[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}Z' || echo "")

            # Try to parse timestamp from filename first (more reliable), fallback to S3 metadata date
            if [ -n "$ISO_TIMESTAMP" ]; then
              # Parse ISO 8601 timestamp from filename
              if ! FILE_TIMESTAMP=$(date -d "$ISO_TIMESTAMP" +%s 2>/dev/null); then
                echo "Warning: Could not parse ISO timestamp from filename ${FILENAME}, trying S3 date"
                if ! FILE_TIMESTAMP=$(date -d "$FILE_DATE" +%s 2>/dev/null); then
                  echo "Warning: Could not parse date for ${FILE_PATH}, skipping"
                  ERRORS=$((ERRORS + 1))
                  continue
                fi
              fi
            else
              # Fallback to S3 metadata date
              if ! FILE_TIMESTAMP=$(date -d "$FILE_DATE" +%s 2>/dev/null); then
                echo "Warning: Could not parse date for ${FILE_PATH}, skipping"
                ERRORS=$((ERRORS + 1))
                continue
              fi
            fi

            # Delete backups older than 30 days
            if [ "$FILE_TIMESTAMP" -lt "$THIRTY_DAYS_AGO" ]; then
              echo "Deleting backup older than 30 days: ${FILE_PATH}"
              if aws s3 rm "s3://${BACKUP_BUCKET}/${FILE_PATH}" --endpoint-url="${AWS_ENDPOINT_URL}" 2>&1; then
                DELETED_OLD=$((DELETED_OLD + 1))
              else
                echo "ERROR: Failed to delete ${FILE_PATH}"
                ERRORS=$((ERRORS + 1))
              fi

            # For backups 8-30 days old, keep only one per day
            elif [ "$FILE_TIMESTAMP" -lt "$SEVEN_DAYS_AGO" ]; then
              # Extract date from ISO 8601 timestamp in filename (YYYY-MM-DD)
              BACKUP_DATE=$(echo "$ISO_TIMESTAMP" | cut -d'T' -f1)

              if [ -z "$BACKUP_DATE" ]; then
                echo "Warning: Could not extract date from timestamp ${ISO_TIMESTAMP}, keeping file"
                KEPT_RECENT=$((KEPT_RECENT + 1))
                continue
              fi

              # Track if we've already kept one backup for this date
              STATE_FILE="/tmp/mongo-cleanup-${BACKUP_DATE}.keep"

              if [ -f "$STATE_FILE" ]; then
                # Already kept one backup for this date, delete this one
                echo "Deleting non-latest daily backup for ${BACKUP_DATE}: ${FILE_PATH}"
                if aws s3 rm "s3://${BACKUP_BUCKET}/${FILE_PATH}" --endpoint-url="${AWS_ENDPOINT_URL}" 2>&1; then
                  DELETED_DAILY=$((DELETED_DAILY + 1))
                else
                  echo "ERROR: Failed to delete ${FILE_PATH}"
                  ERRORS=$((ERRORS + 1))
                fi
              else
                # First backup for this date, keep it and mark as kept
                echo "Keeping daily backup for ${BACKUP_DATE}: ${FILE_PATH}"
                touch "$STATE_FILE"
                KEPT_RECENT=$((KEPT_RECENT + 1))
              fi
            else
              # Recent backup (< 7 days), keep it
              KEPT_RECENT=$((KEPT_RECENT + 1))
            fi
          done

          # Summary report
          # Clean up state files
          rm -f /tmp/mongo-cleanup-*.keep

          echo ""
          echo "=== MongoDB Backup Cleanup Summary ==="
          echo "Deleted (>30 days): ${DELETED_OLD}"
          echo "Deleted (daily consolidation): ${DELETED_DAILY}"
          echo "Kept (recent <7 days): ${KEPT_RECENT}"
          echo "Errors: ${ERRORS}"
          echo "Completed at: $(date -u +%Y-%m-%dT%H:%M:%SZ)"

          # Send email alert if there were errors
          if [ "$ERRORS" -gt 0 ]; then
            ERROR_MSG="MongoDB backup cleanup completed with ${ERRORS} errors. Check logs: sudo journalctl -u mongodb-backup.service -n 200"
            echo "WARNING: $ERROR_MSG"
            /usr/local/bin/send-rate-limited-email.sh "mongo-cleanup" "[WARNING] MongoDB Backup Cleanup Had Errors on $(hostname)" "$ERROR_MSG"
          fi

          echo "MongoDB backup cleanup completed successfully"

    # Create systemd service for MongoDB backup
    - name: Create MongoDB backup systemd service
      copy:
        dest: /etc/systemd/system/mongodb-backup.service
        content: |
          # WARNING: This file is managed by Ansible
          # Manual changes will be overwritten on next deployment
          [Unit]
          Description=MongoDB Backup to Cloudflare R2
          OnFailure=failure-notification@%n.service

          [Service]
          Type=oneshot
          RemainAfterExit=no
          TimeoutStartSec=600
          TimeoutStopSec=30
          Environment="AWS_ACCESS_KEY_ID={{ lookup('env', 'AWS_ACCESS_KEY_ID') }}"
          Environment="AWS_SECRET_ACCESS_KEY={{ lookup('env', 'AWS_SECRET_ACCESS_KEY') }}"
          Environment="AWS_ENDPOINT_URL={{ lookup('env', 'AWS_ENDPOINT_URL') }}"
          Environment="AWS_DEFAULT_REGION={{ lookup('env', 'AWS_DEFAULT_REGION') or 'auto' }}"
          Environment="MONGO_BACKUP_BUCKET={{ lookup('env', 'MONGO_BACKUP_BUCKET') | default('forwardemail-backups', true) }}"
          Environment="BACKUP_SECRET={{ lookup('env', 'BACKUP_SECRET') }}"
          Environment="MONGO_PORT={{ lookup('env', 'MONGO_PORT') | default('27017', true) }}"
          Environment="MSMTP_RCPTS={{ lookup('env', 'MSMTP_RCPTS') | default('security@forwardemail.net', true) }}"
          ExecStart=/usr/local/bin/backup-mongodb.sh
          ExecStartPost=/usr/local/bin/cleanup-mongodb-backups.sh

    # Create systemd timer for MongoDB backup (every 6 hours)
    - name: Create MongoDB backup systemd timer
      copy:
        dest: /etc/systemd/system/mongodb-backup.timer
        content: |
          # WARNING: This file is managed by Ansible
          # Manual changes will be overwritten on next deployment
          [Unit]
          Description=MongoDB Backup Every 6 Hours

          [Timer]
          OnBootSec=15min
          OnUnitActiveSec=6h

          [Install]
          WantedBy=timers.target

    - name: Enable and start MongoDB backup timer
      systemd:
        daemon_reload: true
        name: mongodb-backup.timer
        enabled: true
        state: started

    # ============================================================================
    # POST-DEPLOYMENT INSTRUCTIONS
    # ============================================================================
    - name: Display manual restart instructions
      shell: |
        cat << 'EOF'

        â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
        â•‘                                                                        â•‘
        â•‘                    âš ï¸  MANUAL RESTART REQUIRED âš ï¸                      â•‘
        â•‘                                                                        â•‘
        â•‘  MongoDB configuration has been updated but the service was NOT       â•‘
        â•‘  automatically restarted to prevent disruption.                       â•‘
        â•‘                                                                        â•‘
        â•‘  To apply the new configuration, you must MANUALLY restart MongoDB:   â•‘
        â•‘                                                                        â•‘
        â•‘    sudo systemctl restart mongod                                      â•‘
        â•‘                                                                        â•‘
        â•‘  âš ï¸  WARNING: This will:                                              â•‘
        â•‘    â€¢ Disconnect all active MongoDB connections                        â•‘
        â•‘    â€¢ Cause brief service interruption                                 â•‘
        â•‘    â€¢ May take time if large datasets need to be flushed               â•‘
        â•‘                                                                        â•‘
        â•‘  ðŸ’¡ RECOMMENDATION:                                                   â•‘
        â•‘    â€¢ Schedule restart during low-traffic period                       â•‘
        â•‘    â€¢ Notify team before restarting                                    â•‘
        â•‘    â€¢ Monitor logs: sudo journalctl -u mongod -f                       â•‘
        â•‘                                                                        â•‘
        â•‘  To verify MongoDB is running after restart:                          â•‘
        â•‘    mongosh --tls --tlsCAFile /etc/mongodb/ssl/ca.pem \               â•‘
        â•‘            --host localhost:27017 --eval "db.adminCommand('ping')"   â•‘
        â•‘                                                                        â•‘
        â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        EOF
      changed_when: false
