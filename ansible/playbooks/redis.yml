# Copyright (c) Forward Email LLC
# SPDX-License-Identifier: BUSL-1.1

---
- name: Import security playbook
  import_playbook: security.yml
- name: Import SSH keys playbook
  import_playbook: ssh-keys.yml

- hosts: redis
  name: Certificate Paths
  vars_prompt:
    - name: input_key
      prompt: "Enter path to certificate private key file on local machine (e.g. /path/to/.ssl-key) [REQUIRED]"
      private: false
    - name: input_cert
      prompt: "Enter path to certificate full chain/certificate file on local machine (e.g. /path/to/.ssl-cert) [REQUIRED]"
      private: false
    - name: input_ca
      prompt: "Enter path to certificate CA bundle file on local machine (e.g. /path/to/.ssl-ca) [REQUIRED]"
      private: false
  tasks:
    - name: Fail if key path is empty
      fail:
        msg: "Certificate private key path is required. Please re-run the playbook and provide a valid path."
      when: (input_key is not defined) or (input_key | length == 0)

    - name: Fail if cert path is empty
      fail:
        msg: "Certificate file path is required. Please re-run the playbook and provide a valid path."
      when: (input_cert is not defined) or (input_cert | length == 0)

    - name: Fail if CA path is empty
      fail:
        msg: "CA bundle file path is required. Please re-run the playbook and provide a valid path."
      when: (input_ca is not defined) or (input_ca | length == 0)

    - name: Check if key file exists locally
      local_action: stat path={{ input_key }}
      become: false
      register: local_key_file

    - name: Fail when local key file does not exist
      fail:
        msg: "key file does not exist: {{ input_key }}"
      when: not local_key_file.stat.exists

    - name: Check if cert file exists locally
      local_action: stat path={{ input_cert }}
      become: false
      register: local_cert_file

    - name: Fail when local cert file does not exist
      fail:
        msg: "cert file does not exist: {{ input_cert }}"
      when: not local_cert_file.stat.exists

    - name: Check if CA file exists locally
      local_action: stat path={{ input_ca }}
      become: false
      register: local_ca_file

    - name: Fail when local CA file does not exist
      fail:
        msg: "CA file does not exist: {{ input_ca }}"
      when: not local_ca_file.stat.exists

    - name: Store certificate paths as facts
      set_fact:
        ssl_key_path: "{{ input_key }}"
        ssl_cert_path: "{{ input_cert }}"
        ssl_ca_path: "{{ input_ca }}"

- hosts: redis
  name: Hostname
  become: true
  become_user: root
  tasks:
    - name: Validate required environment variables
      assert:
        that:
          - lookup('env', 'REDIS_HOST') != ''
          - lookup('env', 'REDIS_PASSWORD') != ''
          - lookup('env', 'REDIS_TLS_PORT') != ''
          - lookup('env', 'AWS_ACCESS_KEY_ID') != ''
          - lookup('env', 'AWS_SECRET_ACCESS_KEY') != ''
          - lookup('env', 'AWS_ENDPOINT_URL') != ''
          - lookup('env', 'BACKUP_SECRET') != ''
        fail_msg: |
          Required environment variables are missing for Redis playbook.
          Please ensure the following variables are set in your .env file:
          - REDIS_HOST
          - REDIS_PASSWORD
          - REDIS_TLS_PORT
          - SSL_CERT_PATH
          - SSL_KEY_PATH
          - SSL_CA_PATH
          - AWS_ACCESS_KEY_ID
          - AWS_SECRET_ACCESS_KEY
          - AWS_ENDPOINT_URL
          - BACKUP_SECRET
        quiet: false

    - name: Set hostname
      hostname:
        name: "{{ lookup('env', 'REDIS_HOST') }}"

- hosts: redis
  name: Redis
  become: true
  become_user: root
  handlers:
    - name: Reload UFW
      ufw:
        state: reloaded
    - name: Restart Valkey
      service:
        name: valkey-server
        state: restarted
  tasks:
    # Redis-specific sysctl optimizations
    # Note: THP, ulimits, and base sysctl settings are inherited from security.yml
    - name: Configure Redis-specific sysctl parameters
      ansible.builtin.sysctl:
        name: "{{ item.name }}"
        value: "{{ item.value }}"
        state: present
        reload: true
        sysctl_file: /etc/sysctl.d/99-redis.conf
      loop:
        - { name: 'vm.overcommit_memory', value: '1' }
        - { name: 'net.core.somaxconn', value: '65536' }
        - { name: 'net.ipv4.tcp_max_syn_backlog', value: '65536' }

    # Configure swap for Redis stability
    # Redis official docs: "swap file size is equal to amount of memory on your system"
    # https://redis.io/docs/latest/operate/oss_and_stack/management/admin/
    - name: Get total system memory in MB
      shell: free -m | awk '/^Mem:/{print $2}'
      register: total_memory_mb
      changed_when: false

    - name: Check if swap file exists
      stat:
        path: /swapfile
      register: swapfile_stat

    - name: Check current swap size
      shell: swapon --show=SIZE --noheadings --bytes | head -1
      register: current_swap_bytes
      changed_when: false
      failed_when: false

    - name: Calculate required swap size in bytes
      set_fact:
        required_swap_mb: "{{ total_memory_mb.stdout | int }}"
        required_swap_bytes: "{{ (total_memory_mb.stdout | int) * 1024 * 1024 }}"

    - name: Disable existing swap if size doesn't match
      command: swapoff /swapfile
      when:
        - swapfile_stat.stat.exists
        - current_swap_bytes.stdout != ""
        - current_swap_bytes.stdout | int != required_swap_bytes | int
      ignore_errors: true

    - name: Remove old swap file if size doesn't match
      file:
        path: /swapfile
        state: absent
      when:
        - swapfile_stat.stat.exists
        - current_swap_bytes.stdout != ""
        - current_swap_bytes.stdout | int != required_swap_bytes | int

    - name: Create swap file with size equal to RAM
      command: fallocate -l {{ required_swap_mb }}M /swapfile
      args:
        creates: /swapfile

    - name: Set swap file permissions
      file:
        path: /swapfile
        mode: '0600'
        owner: root
        group: root

    - name: Format swap file
      command: mkswap /swapfile
      when: not swapfile_stat.stat.exists or (current_swap_bytes.stdout | int != required_swap_bytes | int)
      register: mkswap_result
      changed_when: "'Setting up swapspace' in mkswap_result.stdout"

    - name: Enable swap file
      command: swapon /swapfile
      when: mkswap_result is changed

    - name: Add swap to /etc/fstab
      lineinfile:
        path: /etc/fstab
        line: '/swapfile none swap sw 0 0'
        state: present
        regexp: '^/swapfile'

    - name: Set swappiness for Redis (minimize swapping but allow it for safety)
      ansible.builtin.sysctl:
        name: vm.swappiness
        value: '1'
        state: present
        reload: true
        sysctl_file: /etc/sysctl.d/99-redis.conf

    # Install Valkey 8.x from source
    - name: Install build dependencies
      apt:
        name:
          - build-essential
          - tcl
          - pkg-config
          - libssl-dev
        state: present
        update_cache: yes

    - name: Create valkey user
      user:
        name: valkey
        system: yes
        shell: /bin/false
        home: /var/lib/valkey
        create_home: yes

    - name: Create valkey group
      group:
        name: valkey
        system: yes

    - name: Download Valkey 8.0.1 source
      get_url:
        url: https://github.com/valkey-io/valkey/archive/refs/tags/8.0.1.tar.gz
        dest: /tmp/valkey-8.0.1.tar.gz
        checksum: sha256:1e1d6dfbed2f932a87afbc7402be050a73974a9b19a9116897e537a6638e5e1d

    - name: Extract Valkey source
      unarchive:
        src: /tmp/valkey-8.0.1.tar.gz
        dest: /tmp/
        remote_src: yes
        creates: /tmp/valkey-8.0.1

    - name: Compile Valkey
      shell: |
        cd /tmp/valkey-8.0.1
        make BUILD_TLS=yes
      args:
        creates: /tmp/valkey-8.0.1/src/valkey-server

    - name: Install Valkey binaries
      shell: |
        cd /tmp/valkey-8.0.1
        make install PREFIX=/usr
      args:
        creates: /usr/bin/valkey-server

    - name: Create Valkey directories
      file:
        path: "{{ item }}"
        state: directory
        owner: valkey
        group: valkey
        mode: '0755'
      loop:
        - /etc/valkey
        - /var/lib/valkey
        - /var/log/valkey

    - name: Create Valkey systemd service
      copy:
        dest: /etc/systemd/system/valkey-server.service
        content: |
          [Unit]
          Description=Valkey In-Memory Data Store
          After=network.target

          [Service]
          Type=simple
          User=valkey
          Group=valkey
          ExecStart=/usr/bin/valkey-server /etc/valkey/valkey.conf
          ExecStop=/bin/kill -s TERM $MAINPID
          PIDFile=/var/run/valkey/valkey-server.pid
          TimeoutStartSec=90
          TimeoutStopSec=90
          Restart=always
          RuntimeDirectory=valkey
          RuntimeDirectoryMode=0755

          [Install]
          WantedBy=multi-user.target

    - name: Reload systemd
      systemd:
        daemon_reload: yes

    # Create SSL directory for Valkey certificates
    - name: Create /etc/valkey/ssl directory
      file:
        path: /etc/valkey/ssl
        state: directory
        owner: valkey
        group: valkey
        mode: "0750"

    # Copy SSL certificates directly from local machine to Valkey directory
    - name: Copy SSL certificate to Valkey directory
      copy:
        src: "{{ hostvars[inventory_hostname]['ssl_cert_path'] }}"
        dest: /etc/valkey/ssl/valkey.crt
        owner: valkey
        group: valkey
        mode: "0400"

    - name: Copy SSL private key to Valkey directory
      copy:
        src: "{{ hostvars[inventory_hostname]['ssl_key_path'] }}"
        dest: /etc/valkey/ssl/valkey.key
        owner: valkey
        group: valkey
        mode: "0400"

    - name: Copy CA certificate to Valkey directory
      copy:
        src: "{{ hostvars[inventory_hostname]['ssl_ca_path'] }}"
        dest: /etc/valkey/ssl/ca.pem
        owner: valkey
        group: valkey
        mode: "0400"

    - name: Ensure Valkey is stopped before configuration
      service:
        name: valkey-server
        state: stopped
      ignore_errors: yes

    # Calculate dynamic resource limits
    - name: Get total system memory in MB
      shell: free -m | awk '/^Mem:/{print $2}'
      register: total_memory_mb
      changed_when: false

    - name: Calculate maxmemory (75% of total RAM)
      set_fact:
        valkey_maxmemory_mb: "{{ (total_memory_mb.stdout | int * 0.75) | int }}"

    - name: Get number of CPU cores
      shell: nproc
      register: cpu_cores
      changed_when: false

    - name: Set io-threads (number of CPU cores, max 8)
      set_fact:
        valkey_io_threads: "{{ [cpu_cores.stdout | int, 8] | min }}"

    - name: Create base Valkey configuration file
      copy:
        dest: /etc/valkey/valkey.conf
        owner: valkey
        group: valkey
        mode: '0640'
        force: no
        content: |
          # Valkey configuration file
          # Generated by Ansible - base configuration with security hardening
          # Additional custom settings are managed in the ANSIBLE MANAGED BLOCK below

          ################################## GENERAL #####################################

          # By default the server does not run as a daemon.
          daemonize no

          # Supervised by systemd
          supervised systemd

          # PID file location
          pidfile /var/run/valkey/valkey-server.pid

          # Logging
          loglevel notice
          logfile /var/log/valkey/valkey-server.log

          # Set the number of databases
          databases 16

          ################################## SNAPSHOTTING ################################

          # Save the DB to disk (handled by ANSIBLE MANAGED BLOCK)
          # Default: save 3600 1 300 100 60 10000

          # Compression of string objects using LZF when dump .rdb databases
          rdbcompression yes

          # RDB file checksum
          rdbchecksum yes

          # The filename where to dump the DB
          dbfilename dump.rdb

          # The working directory
          dir /var/lib/valkey

          ################################# REPLICATION ##################################

          # Disable replication by default
          # replicaof <masterip> <masterport>

          ################################## SECURITY ####################################

          # Require clients to authenticate (password set in ANSIBLE MANAGED BLOCK)
          # requirepass <password>

          # Disable dangerous commands
          rename-command FLUSHDB ""
          rename-command FLUSHALL ""
          # rename-command KEYS ""
          rename-command CONFIG ""
          rename-command SHUTDOWN ""
          rename-command BGREWRITEAOF ""
          rename-command BGSAVE ""
          rename-command SAVE ""
          rename-command DEBUG ""

          ################################### CLIENTS ####################################

          # Max number of connected clients (set in ANSIBLE MANAGED BLOCK)
          # maxclients 10000

          ############################## MEMORY MANAGEMENT ###############################

          # Maximum memory limit (75% of total system RAM)
          maxmemory {{ valkey_maxmemory_mb }}mb

          # Memory eviction policy
          maxmemory-policy allkeys-lru

          # LRU and minimal TTL algorithms are not precise but approximated
          maxmemory-samples 5

          ############################# LAZY FREEING ####################################

          # Lazy freeing to avoid blocking on DEL
          lazyfree-lazy-eviction yes
          lazyfree-lazy-expire yes
          lazyfree-lazy-server-del yes
          replica-lazy-flush yes

          ############################## APPEND ONLY MODE ###############################

          # AOF persistence (configured in ANSIBLE MANAGED BLOCK)
          # appendonly yes
          # appendfsync everysec

          # Rewrite the AOF file in background when it gets too big
          auto-aof-rewrite-percentage 100
          auto-aof-rewrite-min-size 64mb

          # Load truncated AOF file
          aof-load-truncated yes

          # Use RDB-AOF hybrid format
          aof-use-rdb-preamble yes

          ################################ THREADED I/O #################################

          # Enable threaded I/O for better performance
          # Number of I/O threads (dynamically set to number of CPU cores, max 8)
          io-threads {{ valkey_io_threads }}
          io-threads-do-reads yes

          ################################## SLOW LOG ###################################

          # Log queries slower than this many microseconds
          slowlog-log-slower-than 10000
          slowlog-max-len 128

          ################################ LATENCY MONITOR ##############################

          # Latency monitoring
          latency-monitor-threshold 100

          ############################# EVENT NOTIFICATION ###############################

          # Keyspace notifications (disabled by default for performance)
          notify-keyspace-events ""

          ############################### ADVANCED CONFIG ################################

          # Hashes are encoded using a memory efficient data structure when small
          hash-max-listpack-entries 512
          hash-max-listpack-value 64

          # Lists are encoded in a special way to save space
          list-max-listpack-size -2
          list-compress-depth 0

          # Sets have a special encoding when composed of just strings
          set-max-intset-entries 512
          set-max-listpack-entries 128
          set-max-listpack-value 64

          # Sorted sets are encoded to save space
          zset-max-listpack-entries 128
          zset-max-listpack-value 64

          # HyperLogLog sparse representation bytes limit
          hll-sparse-max-bytes 3000

          # Streams macro node max size / items
          stream-node-max-bytes 4096
          stream-node-max-entries 100

          # Active rehashing
          activerehashing yes

          # Client output buffer limits
          client-output-buffer-limit normal 0 0 0
          client-output-buffer-limit replica 256mb 64mb 60
          client-output-buffer-limit pubsub 32mb 8mb 60

          # Frequency of rehashing the main dict
          hz 10

          # Enable active defragmentation
          activedefrag yes
          active-defrag-ignore-bytes 100mb
          active-defrag-threshold-lower 10
          active-defrag-threshold-upper 100
          active-defrag-cycle-min 5
          active-defrag-cycle-max 75

    - name: Configure Valkey
      blockinfile:
        path: /etc/valkey/valkey.conf
        marker: "# {mark} ANSIBLE MANAGED BLOCK - VALKEY CONFIG"
        create: yes
        block: |
          # Bind to all interfaces
          bind 0.0.0.0 ::

          # Authentication
          requirepass {{ lookup('env', 'REDIS_PASSWORD') }}

          # TLS/SSL Configuration
          tls-port {{ lookup('env', 'REDIS_TLS_PORT') }}
          port 0
          tls-cert-file /etc/valkey/ssl/valkey.crt
          tls-key-file /etc/valkey/ssl/valkey.key
          tls-ca-cert-file /etc/valkey/ssl/ca.pem
          tls-auth-clients no

          # Persistence
          appendonly yes
          appendfsync everysec
          save 900 1
          save 300 10
          save 60 10000

          # Performance Optimizations
          tcp-backlog 65536
          tcp-keepalive 0
          maxclients 10000
      notify: Restart Valkey

    - name: Ensure Valkey is enabled and started
      service:
        name: valkey-server
        state: started
        enabled: yes

    # UFW Configuration
    - name: Enable ufw
      ufw:
        state: enabled
        policy: deny
        direction: incoming

    - name: Limit ufw ssh
      ufw:
        rule: limit
        port: 22
        proto: tcp

    - name: Allow ssh
      ufw:
        rule: allow
        port: 22
        proto: tcp

    # Fetch IP whitelist and configure UFW
    - name: Fetch IP whitelist from forwardemail.net
      uri:
        url: https://forwardemail.net/ips/v4.txt?comments=false
        return_content: true
      register: ip_whitelist_response

    - name: Parse IP whitelist
      set_fact:
        allowed_ips: "{{ ip_whitelist_response.content.split('\n') | select('match', '^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+$') | list }}"

    - name: Allow Redis TLS port from whitelisted IPs
      ufw:
        rule: allow
        from_ip: "{{ item }}"
        to_port: "{{ lookup('env', 'REDIS_TLS_PORT') }}"
        proto: tcp
        comment: "Auto-whitelist Redis TLS"
      loop: "{{ allowed_ips }}"
      notify: Reload UFW

    # Install UFW whitelist update script
    - name: Create UFW whitelist update script
      copy:
        dest: /usr/local/bin/update-redis-ufw-whitelist.sh
        mode: "0755"
        content: |
          #!/bin/bash
          set -e

          # Fetch current IP list
          NEW_IPS=$(curl -s https://forwardemail.net/ips/v4.txt?comments=false | grep -E '^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$')

          # Get current UFW rules for Redis TLS port
          REDIS_TLS_PORT="${REDIS_TLS_PORT:-6380}"
          CURRENT_IPS=$(ufw status | grep "${REDIS_TLS_PORT}/tcp" | grep "ALLOW" | awk '{print $3}' | sort -u)

          # Track if changes were made
          CHANGED=0

          # Add new IPs
          for ip in $NEW_IPS; do
            if ! echo "$CURRENT_IPS" | grep -q "^${ip}$"; then
              ufw allow from "$ip" to any port "$REDIS_TLS_PORT" proto tcp comment "Auto-whitelist Redis TLS"
              CHANGED=1
            fi
          done

          # Remove old IPs (not in new list)
          for ip in $CURRENT_IPS; do
            if ! echo "$NEW_IPS" | grep -q "^${ip}$"; then
              # Find and delete the rule
              RULE_NUM=$(ufw status numbered | grep "${REDIS_TLS_PORT}/tcp" | grep "$ip" | grep -oP '^\[\s*\K[0-9]+' | head -1)
              if [ -n "$RULE_NUM" ]; then
                echo "y" | ufw delete "$RULE_NUM"
                CHANGED=1
              fi
            fi
          done

          # Reload UFW if changes were made
          if [ $CHANGED -eq 1 ]; then
            ufw reload
          fi

    # Create systemd timer for UFW whitelist updates
    - name: Create UFW whitelist update systemd service
      copy:
        dest: /etc/systemd/system/redis-ufw-whitelist-update.service
        content: |
          [Unit]
          Description=Update Redis UFW IP Whitelist

          [Service]
          Type=oneshot
          ExecStart=/usr/local/bin/update-redis-ufw-whitelist.sh

    - name: Create UFW whitelist update systemd timer
      copy:
        dest: /etc/systemd/system/redis-ufw-whitelist-update.timer
        content: |
          [Unit]
          Description=Update Redis UFW IP Whitelist Every 10 Minutes

          [Timer]
          OnBootSec=5min
          OnUnitActiveSec=10min

          [Install]
          WantedBy=timers.target

    - name: Enable and start UFW whitelist update timer
      systemd:
        daemon_reload: true
        name: redis-ufw-whitelist-update.timer
        enabled: true
        state: started

    # Install AWS CLI and GPG dependencies
    - name: Install AWS CLI and GPG dependencies
      apt:
        name:
          - python3-pip
          - unzip
          - gnupg
        update_cache: true

    - name: Install AWS CLI
      shell: |
        if ! command -v aws &> /dev/null; then
          curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "/tmp/awscliv2.zip"
          unzip -q /tmp/awscliv2.zip -d /tmp
          /tmp/aws/install
          rm -rf /tmp/aws /tmp/awscliv2.zip
        fi
      args:
        creates: /usr/local/bin/aws

    # Create Redis backup script
    - name: Create Redis backup script
      copy:
        dest: /usr/local/bin/backup-redis.sh
        mode: "0755"
        content: |
          #!/bin/bash
          set -e

          # Environment variables (set via systemd service or environment)
          AWS_ACCESS_KEY_ID="${AWS_ACCESS_KEY_ID}"
          AWS_SECRET_ACCESS_KEY="${AWS_SECRET_ACCESS_KEY}"
          AWS_ENDPOINT_URL="${AWS_ENDPOINT_URL}"
          BACKUP_BUCKET="${REDIS_BACKUP_BUCKET:-forwardemail-backups}"
          BACKUP_SECRET="${BACKUP_SECRET}"
          REDIS_DATA_DIR="${REDIS_DATA_DIR:-/var/lib/valkey}"

          # Check if BACKUP_SECRET is set
          if [ -z "$BACKUP_SECRET" ]; then
            echo "Error: BACKUP_SECRET environment variable is not set"
            exit 1
          fi

          # Timestamp and path
          TIMESTAMP=$(date +%Y/%m/%d/%H)
          BACKUP_NAME="redis-backup-$(date +%Y%m%d-%H%M%S).rdb.gpg"
          S3_PATH="s3://${BACKUP_BUCKET}/redis/${TIMESTAMP}/${BACKUP_NAME}"

          # Trigger Valkey BGSAVE
          valkey-cli -a "${REDIS_PASSWORD}" BGSAVE

          # Wait for BGSAVE to complete
          while [ "$(valkey-cli -a "${REDIS_PASSWORD}" LASTSAVE)" == "$(valkey-cli -a "${REDIS_PASSWORD}" LASTSAVE)" ]; do
            sleep 1
          done

          # Give it a moment to finish writing
          sleep 2

          # Encrypt and upload RDB file to S3
          gpg --symmetric --cipher-algo AES256 --batch --yes --passphrase "$BACKUP_SECRET" < "${REDIS_DATA_DIR}/dump.rdb" | \
            aws s3 cp - "${S3_PATH}" --endpoint-url="${AWS_ENDPOINT_URL}"

          echo "Redis encrypted backup completed: ${S3_PATH}"

    # Create Redis backup cleanup script
    - name: Create Redis backup cleanup script
      copy:
        dest: /usr/local/bin/cleanup-redis-backups.sh
        mode: "0755"
        content: |
          #!/bin/bash
          set -e

          # Environment variables
          AWS_ACCESS_KEY_ID="${AWS_ACCESS_KEY_ID}"
          AWS_SECRET_ACCESS_KEY="${AWS_SECRET_ACCESS_KEY}"
          AWS_ENDPOINT_URL="${AWS_ENDPOINT_URL}"
          BACKUP_BUCKET="${REDIS_BACKUP_BUCKET:-forwardemail-backups}"

          # Calculate dates
          THIRTY_DAYS_AGO=$(date -d "30 days ago" +%s)
          SEVEN_DAYS_AGO=$(date -d "7 days ago" +%s)

          # List all backups
          aws s3 ls s3://${BACKUP_BUCKET}/redis/ --recursive --endpoint-url="${AWS_ENDPOINT_URL}" | while read -r line; do
            FILE_DATE=$(echo "$line" | awk '{print $1}')
            FILE_PATH=$(echo "$line" | awk '{print $4}')
            FILE_TIMESTAMP=$(date -d "$FILE_DATE" +%s)

            # Delete backups older than 30 days
            if [ "$FILE_TIMESTAMP" -lt "$THIRTY_DAYS_AGO" ]; then
              aws s3 rm "s3://${BACKUP_BUCKET}/${FILE_PATH}" --endpoint-url="${AWS_ENDPOINT_URL}"
              echo "Deleted old backup: ${FILE_PATH}"
            # For backups 8-30 days old, keep only one per day (delete others)
            elif [ "$FILE_TIMESTAMP" -lt "$SEVEN_DAYS_AGO" ]; then
              # Extract date from path (YYYY/MM/DD)
              BACKUP_DATE=$(echo "$FILE_PATH" | grep -oP 'redis/\K[0-9]{4}/[0-9]{2}/[0-9]{2}')

              # Get all backups for this date
              DAILY_BACKUPS=$(aws s3 ls "s3://${BACKUP_BUCKET}/redis/${BACKUP_DATE}/" --recursive --endpoint-url="${AWS_ENDPOINT_URL}" | awk '{print $4}' | sort)

              # Keep only the latest backup for the day
              LATEST_BACKUP=$(echo "$DAILY_BACKUPS" | tail -1)

              # Delete all except the latest
              for backup in $DAILY_BACKUPS; do
                if [ "$backup" != "$LATEST_BACKUP" ]; then
                  aws s3 rm "s3://${BACKUP_BUCKET}/${backup}" --endpoint-url="${AWS_ENDPOINT_URL}"
                  echo "Deleted non-latest daily backup: ${backup}"
                fi
              done
            fi
          done

          echo "Redis backup cleanup completed"

    # Create systemd service for Redis backup
    - name: Create Redis backup systemd service
      copy:
        dest: /etc/systemd/system/redis-backup.service
        content: |
          [Unit]
          Description=Redis Backup to Cloudflare R2

          [Service]
          Type=oneshot
          Environment="AWS_ACCESS_KEY_ID={{ lookup('env', 'AWS_ACCESS_KEY_ID') }}"
          Environment="AWS_SECRET_ACCESS_KEY={{ lookup('env', 'AWS_SECRET_ACCESS_KEY') }}"
          Environment="AWS_ENDPOINT_URL={{ lookup('env', 'AWS_ENDPOINT_URL') }}"
          Environment="REDIS_BACKUP_BUCKET={{ lookup('env', 'REDIS_BACKUP_BUCKET') | default('forwardemail-backups', true) }}"
          Environment="BACKUP_SECRET={{ lookup('env', 'BACKUP_SECRET') }}"
          Environment="REDIS_PASSWORD={{ lookup('env', 'REDIS_PASSWORD') }}"
          Environment="REDIS_DATA_DIR={{ lookup('env', 'REDIS_DATA_DIR') | default('/var/lib/valkey', true) }}"
          ExecStart=/usr/local/bin/backup-redis.sh
          ExecStartPost=/usr/local/bin/cleanup-redis-backups.sh

    # Create systemd timer for Redis backup (every 6 hours)
    - name: Create Redis backup systemd timer
      copy:
        dest: /etc/systemd/system/redis-backup.timer
        content: |
          [Unit]
          Description=Redis Backup Every 6 Hours

          [Timer]
          OnBootSec=15min
          OnUnitActiveSec=6h

          [Install]
          WantedBy=timers.target

    - name: Enable and start Redis backup timer
      systemd:
        daemon_reload: true
        name: redis-backup.timer
        enabled: true
        state: started
